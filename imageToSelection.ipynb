{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modelimizi şeçiyoruz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YOLO(\"yolov8m.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \"runs/detect/predict\" kısmına çıktıyı kaydediyor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Results saved to \u001b[1m/Users/abdulbarisoylemez/runs/detect/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results=model.predict(source='/Users/abdulbarisoylemez/Visual code /yoloOne/object detection yolov8/image/1.JPG',save=True,verbose=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tespit etiğimiz nesnelrin etrafına çizgi çizmemiz için import ediyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### modelde toplam 80 fraklı nesneyi tespit etme özeliğine sahip onların listesi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "         'hair drier', 'toothbrush' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('image/1.JPG')\n",
    "rgb_img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "results = model(rgb_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seçtiğimiz fotografın matrik karşılığına bakalım "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " orig_img: array([[[212, 207, 204],\n",
       "         [213, 208, 205],\n",
       "         [214, 209, 206],\n",
       "         ...,\n",
       "         [206, 203, 196],\n",
       "         [206, 203, 196],\n",
       "         [206, 203, 196]],\n",
       " \n",
       "        [[213, 208, 205],\n",
       "         [213, 208, 205],\n",
       "         [213, 208, 205],\n",
       "         ...,\n",
       "         [206, 203, 196],\n",
       "         [206, 203, 196],\n",
       "         [206, 203, 196]],\n",
       " \n",
       "        [[212, 207, 204],\n",
       "         [213, 208, 205],\n",
       "         [214, 209, 206],\n",
       "         ...,\n",
       "         [206, 203, 196],\n",
       "         [206, 203, 196],\n",
       "         [206, 203, 196]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[150, 140, 141],\n",
       "         [151, 141, 142],\n",
       "         [151, 141, 142],\n",
       "         ...,\n",
       "         [120, 111, 106],\n",
       "         [110, 101,  96],\n",
       "         [104,  95,  90]],\n",
       " \n",
       "        [[151, 142, 143],\n",
       "         [152, 143, 144],\n",
       "         [153, 143, 144],\n",
       "         ...,\n",
       "         [143, 134, 129],\n",
       "         [138, 129, 124],\n",
       "         [129, 120, 115]],\n",
       " \n",
       "        [[154, 145, 146],\n",
       "         [155, 146, 147],\n",
       "         [154, 146, 144],\n",
       "         ...,\n",
       "         [142, 133, 128],\n",
       "         [143, 132, 128],\n",
       "         [141, 130, 126]]], dtype=uint8)\n",
       " orig_shape: (2448, 3264)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 3.130197525024414, 'inference': 1067.3961639404297, 'postprocess': 1.3229846954345703}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### nesnelerin konumlarını belirliyor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "boxes: tensor([[2.3279e+03, 1.0007e+03, 2.6470e+03, 1.8992e+03, 9.0788e-01, 0.0000e+00],\n",
       "        [1.0769e+03, 9.2817e+02, 1.4192e+03, 1.8950e+03, 9.0020e-01, 0.0000e+00],\n",
       "        [1.7149e+03, 1.2387e+03, 2.0694e+03, 1.9816e+03, 8.9922e-01, 0.0000e+00],\n",
       "        [8.2798e+02, 9.3290e+02, 1.1553e+03, 1.8286e+03, 8.9670e-01, 0.0000e+00],\n",
       "        [2.0678e+03, 9.8112e+02, 2.4517e+03, 1.8723e+03, 8.7354e-01, 0.0000e+00],\n",
       "        [5.0509e+02, 9.2497e+02, 8.7357e+02, 1.8558e+03, 8.7276e-01, 0.0000e+00],\n",
       "        [2.5744e+03, 9.4998e+02, 2.9594e+03, 1.9113e+03, 8.6489e-01, 0.0000e+00],\n",
       "        [1.3311e+03, 9.2951e+02, 1.7404e+03, 1.9000e+03, 8.4362e-01, 0.0000e+00],\n",
       "        [1.6103e+03, 9.5132e+02, 1.8288e+03, 1.4744e+03, 8.0100e-01, 0.0000e+00],\n",
       "        [1.8136e+03, 9.3018e+02, 2.1126e+03, 1.5796e+03, 6.1452e-01, 0.0000e+00],\n",
       "        [1.8811e+03, 1.7579e+03, 2.0898e+03, 1.8461e+03, 4.1314e-01, 2.9000e+01]])\n",
       "cls: tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 29.])\n",
       "conf: tensor([0.9079, 0.9002, 0.8992, 0.8967, 0.8735, 0.8728, 0.8649, 0.8436, 0.8010, 0.6145, 0.4131])\n",
       "data: tensor([[2.3279e+03, 1.0007e+03, 2.6470e+03, 1.8992e+03, 9.0788e-01, 0.0000e+00],\n",
       "        [1.0769e+03, 9.2817e+02, 1.4192e+03, 1.8950e+03, 9.0020e-01, 0.0000e+00],\n",
       "        [1.7149e+03, 1.2387e+03, 2.0694e+03, 1.9816e+03, 8.9922e-01, 0.0000e+00],\n",
       "        [8.2798e+02, 9.3290e+02, 1.1553e+03, 1.8286e+03, 8.9670e-01, 0.0000e+00],\n",
       "        [2.0678e+03, 9.8112e+02, 2.4517e+03, 1.8723e+03, 8.7354e-01, 0.0000e+00],\n",
       "        [5.0509e+02, 9.2497e+02, 8.7357e+02, 1.8558e+03, 8.7276e-01, 0.0000e+00],\n",
       "        [2.5744e+03, 9.4998e+02, 2.9594e+03, 1.9113e+03, 8.6489e-01, 0.0000e+00],\n",
       "        [1.3311e+03, 9.2951e+02, 1.7404e+03, 1.9000e+03, 8.4362e-01, 0.0000e+00],\n",
       "        [1.6103e+03, 9.5132e+02, 1.8288e+03, 1.4744e+03, 8.0100e-01, 0.0000e+00],\n",
       "        [1.8136e+03, 9.3018e+02, 2.1126e+03, 1.5796e+03, 6.1452e-01, 0.0000e+00],\n",
       "        [1.8811e+03, 1.7579e+03, 2.0898e+03, 1.8461e+03, 4.1314e-01, 2.9000e+01]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (2448, 3264)\n",
       "shape: torch.Size([11, 6])\n",
       "xywh: tensor([[2487.4263, 1449.9502,  319.1355,  898.4423],\n",
       "        [1248.0597, 1411.5610,  342.3655,  966.7811],\n",
       "        [1892.1636, 1610.1289,  354.5304,  742.9514],\n",
       "        [ 991.6577, 1380.7535,  327.3604,  895.7134],\n",
       "        [2259.7505, 1426.6890,  383.9363,  891.1334],\n",
       "        [ 689.3296, 1390.3824,  368.4846,  930.8190],\n",
       "        [2766.9033, 1430.6469,  384.9885,  961.3294],\n",
       "        [1535.7316, 1414.7429,  409.2981,  970.4580],\n",
       "        [1719.5730, 1212.8389,  218.5103,  523.0436],\n",
       "        [1963.0978, 1254.8911,  298.9846,  649.4266],\n",
       "        [1985.4426, 1802.0123,  208.7002,   88.1382]])\n",
       "xywhn: tensor([[0.7621, 0.5923, 0.0978, 0.3670],\n",
       "        [0.3824, 0.5766, 0.1049, 0.3949],\n",
       "        [0.5797, 0.6577, 0.1086, 0.3035],\n",
       "        [0.3038, 0.5640, 0.1003, 0.3659],\n",
       "        [0.6923, 0.5828, 0.1176, 0.3640],\n",
       "        [0.2112, 0.5680, 0.1129, 0.3802],\n",
       "        [0.8477, 0.5844, 0.1179, 0.3927],\n",
       "        [0.4705, 0.5779, 0.1254, 0.3964],\n",
       "        [0.5268, 0.4954, 0.0669, 0.2137],\n",
       "        [0.6014, 0.5126, 0.0916, 0.2653],\n",
       "        [0.6083, 0.7361, 0.0639, 0.0360]])\n",
       "xyxy: tensor([[2327.8584, 1000.7290, 2646.9939, 1899.1713],\n",
       "        [1076.8770,  928.1704, 1419.2424, 1894.9515],\n",
       "        [1714.8983, 1238.6532, 2069.4287, 1981.6046],\n",
       "        [ 827.9775,  932.8969, 1155.3379, 1828.6102],\n",
       "        [2067.7822,  981.1222, 2451.7185, 1872.2556],\n",
       "        [ 505.0873,  924.9730,  873.5719, 1855.7920],\n",
       "        [2574.4092,  949.9821, 2959.3977, 1911.3115],\n",
       "        [1331.0825,  929.5139, 1740.3806, 1899.9719],\n",
       "        [1610.3179,  951.3171, 1828.8281, 1474.3607],\n",
       "        [1813.6055,  930.1779, 2112.5901, 1579.6045],\n",
       "        [1881.0925, 1757.9432, 2089.7927, 1846.0814]])\n",
       "xyxyn: tensor([[0.7132, 0.4088, 0.8110, 0.7758],\n",
       "        [0.3299, 0.3792, 0.4348, 0.7741],\n",
       "        [0.5254, 0.5060, 0.6340, 0.8095],\n",
       "        [0.2537, 0.3811, 0.3540, 0.7470],\n",
       "        [0.6335, 0.4008, 0.7511, 0.7648],\n",
       "        [0.1547, 0.3778, 0.2676, 0.7581],\n",
       "        [0.7887, 0.3881, 0.9067, 0.7808],\n",
       "        [0.4078, 0.3797, 0.5332, 0.7761],\n",
       "        [0.4934, 0.3886, 0.5603, 0.6023],\n",
       "        [0.5556, 0.3800, 0.6472, 0.6453],\n",
       "        [0.5763, 0.7181, 0.6403, 0.7541]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sol ust ve sağ alt köşe kordinatlarını belirliyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2327.8584, 1000.7290, 2646.9939, 1899.1713],\n",
       "        [1076.8770,  928.1704, 1419.2424, 1894.9515],\n",
       "        [1714.8983, 1238.6532, 2069.4287, 1981.6046],\n",
       "        [ 827.9775,  932.8969, 1155.3379, 1828.6102],\n",
       "        [2067.7822,  981.1222, 2451.7185, 1872.2556],\n",
       "        [ 505.0873,  924.9730,  873.5719, 1855.7920],\n",
       "        [2574.4092,  949.9821, 2959.3977, 1911.3115],\n",
       "        [1331.0825,  929.5139, 1740.3806, 1899.9719],\n",
       "        [1610.3179,  951.3171, 1828.8281, 1474.3607],\n",
       "        [1813.6055,  930.1779, 2112.5901, 1579.6045],\n",
       "        [1881.0925, 1757.9432, 2089.7927, 1846.0814]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes.xyxy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ilk değerimize bakalım "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,y1,x2,y2=results[0].boxes.xyxy[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2327.8584)  and  tensor(1000.7290)\n"
     ]
    }
   ],
   "source": [
    "print(x1,\" and \",y1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resim üzerinde object tespiti yapalım "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('image/1.JPG')\n",
    "rgb_img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "results = model(rgb_img) \n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "for i in range(len(results[0].boxes)):\n",
    "    x1,y1,x2,y2=results[0].boxes.xyxy[i] # konumlarını alıyoruz \n",
    "    score=results[0].boxes.conf[i] # score bilgisi\n",
    "    label=results[0].boxes.cls[i]  # etiket bilgisini alıyoruz\n",
    "    x1,y1,x2,y2,score,label=int(x1),int(y1),int(x2),int(y2),float(score),int(label)  # tensor formatlarından kurtarıyoruz \n",
    "    name=labels[label] # sınıfını tespit ediyoruz \n",
    "    if score<0.4 and name!=\"person\": # score değeri 2 ve üzerinde olanlar gösterilecek\n",
    "        continue\n",
    "\n",
    "\n",
    "    cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),3) # nesenin kordinatlarını alarak bir kutu çiziyoruz \n",
    "    text= name+' '+str(format(score, '.2f'))  # scor bilgisini ve adını yazıyoruz \n",
    "    cv2.putText(img, text,(x1, y1-10), font, 1, (0,0,255), 3) # text metinimizi ekranda putText metodu ile yazıyoruz \n",
    "    \n",
    "    if cv2.waitKey(1) & 0XFF==ord(\"q\"):\n",
    "        break\n",
    "cv2.imshow(\"Windows\",img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
